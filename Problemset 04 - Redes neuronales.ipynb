{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJECUTA ESTA CELDA PARA AUTENTICARTE CON TU CUENTA DE GMAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mooclib import *\n",
    "import inspect, urllib\n",
    "html, auth_code, userinfo = google_authenticate(PORT_NUMBER=8080)\n",
    "html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EJERCICIO 1: Codificación de parámetros\n",
    "\n",
    "Dado un dataset con $n$ columnas y una red neuronal con una sola capa de $h$ neuronas, los pesos de las conexiones y los términos de **bias** son los siguientes:\n",
    "\n",
    "- $\\mathbf{b}_1 \\in \\mathbb{R}^h$ son los términos de *bias* de la primera fase\n",
    "- $\\mathbf{W}_1 \\in \\mathbb{R}^{n \\times h}$ son los pesos de las conexiones de la primera fase\n",
    "- $b_1 \\in \\mathbb{R}$ es el término *bias* de la segunda fase\n",
    "- $\\mathbf{W}_2 \\in \\mathbb{R}^{h}$ son los pesos de las conexiones de la segunda fase\n",
    "\n",
    "implementa las siguientes dos funciones para que codifiquen y descodifiquen los parámetros anteriores en un único vector de parámetros de forma que:\n",
    "\n",
    "- `encode` devuelva un vector de $1+2h+h k$ elementos donde los primeros $h$ elementos corresponden a $\\mathbf{b}_1$, el siguiente elmento al valor de $b_2$, los siguientes $nh$ elementos a los elementos de $\\mathbf{W}_1$ linearizados y el resto de elementos a $\\mathbf{W}_2$. Dado un array `numpy` `A`, usa la función `A.flatten()` para linearizarlo.\n",
    "\n",
    "- `decode` acepte un vector como el anterior y extraiga los elementos $\\mathbf{b}_1, b_2, \\mathbf{W}_1$ y $\\mathbf{W}_2$. Dado un array `numpy` `A`, usa la función `A.reshape` para _deslinearizarlo_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode(b1, b2, W1, W2): \n",
    "    encoded_params = ....\n",
    "    return encoded_params\n",
    "\n",
    "def decode(params, nb_cols, h_units):\n",
    "    b1 = ...\n",
    "    b2 = ...\n",
    "    W1 = ...\n",
    "    W2 = ...\n",
    "    return b1, b2, W1, W2\n",
    "\n",
    "import urllib, inspect\n",
    "src1 = urllib.quote_plus(inspect.getsource(encode)+\"\\n\"+\\\n",
    "                         inspect.getsource(decode))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comprueba tu código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def random_params(nb_cols, h_units):\n",
    "    W1 = np.random.random(size=(nb_cols,h_units))\n",
    "    b1 = np.random.random(size=h_units)\n",
    "\n",
    "    W2 = np.random.random(size=(h_units,1))\n",
    "    b2 = np.random.random()\n",
    "    return b1,b2,W1,W2\n",
    "import numpy as np\n",
    "b1, b2, W1, W2 = random_params(3,4)\n",
    "print \"shapes\", b1.shape, b2, W1.shape, W2.shape\n",
    "params = encode(b1,b2,W1,W2)\n",
    "print \"encoded params\", params\n",
    "eb1, eb2, eW1, eW2 = decode(params, 3,4) \n",
    "print \"ALL OK?\", len(params) == 21 and np.allclose(eb1,b1) and np.allclose(eb2,b2) and np.allclose(eW1, W1) and np.allclose(eW2, W2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### evaluate your answer before submitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!./run CHECK_SOLUTION PS4_1 $src1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### submit your answer (you must be connected to internet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!./run SUBMIT_SOLUTION PS4_1 $src1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EJERCICIO 2: Funciones de estimación de probabilidad y coste (con regularización)\n",
    "\n",
    "Dada una neuronal de una sola capa, implementa:\n",
    "- la función de estimación de probabilidad a la clase 1 de cualquier dato ($\\hat{y}$) \n",
    "- la función de coste ($J$) \n",
    "\n",
    "según la siguiente definición\n",
    "\n",
    "$$\\hat{y} = g(\\mathbf{W}_2 \\cdot \\tanh(\\mathbf{x^T} \\cdot \\mathbf{W}_1 + \\mathbf{b}_1) + b_2)$$\n",
    "\n",
    "$$J(\\mathbf{b}_1, b_2, \\mathbf{W}_1, \\mathbf{W}_2) = \\frac{1}{m}\\sum_{i=0}^{m-1} (\\hat{y}-y)^2 + \\lambda \\left[ || \\mathbf{b}_1||^2 + b_2^2 + ||\\mathbf{W}_1||^2 + ||\\mathbf{W}_2||^2\\right]$$\n",
    "\n",
    "observa que la función de coste contiene un conjunto de términos regulados por $\\lambda$ (y que están fuera de la sumatoria). Dado un vector o matriz $\\mathbf{T}$, su norma al cuadrado se denota por $||\\mathbf{T}||^2 \\in \\mathbb{R}$ y se calcula elevando todos sus elementos al cuadrado y obteniendo su suma. Este $\\lambda$ es el argumento `reg` de la función `cost`.\n",
    "\n",
    "el argumento `params` contiene el vector de parámetros según lo generaría la función `encode` del ejercicio anterior, con lo que tendrás que llamar a `decode` dentro de tu implementación para obtener los pesos de las conexiones y los términos de bias.\n",
    "\n",
    "la función `y_hat` ha de funcionar con una matriz `X` en el que en cada fila hay un dato y devolver un vector con la estiamción de probabilidad de cada dato. **ESTE VECTOR HA DE TENER UNA DIMENSION** (`len(shape)`=1)\n",
    "\n",
    "la función $tanh$ la tienes `numpy` como `np.tanh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode(params, nb_cols, h_units):\n",
    "    b1 = ...\n",
    "    b2 = ...\n",
    "    W1 = ...\n",
    "    W2 = ...\n",
    "    return b1, b2, W1, W2\n",
    "\n",
    "def y_hat(params, nb_cols, h_units, X):\n",
    "    def sigm(x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    b1,b2,W1,W2 = decode(...)\n",
    "    result = ...\n",
    "    return result\n",
    "\n",
    "def cost(X, y, params, reg, nb_cols, h_units):\n",
    "    c = ...\n",
    "    return ...\n",
    "\n",
    "import urllib, inspect\n",
    "src2 = urllib.quote_plus(inspect.getsource(decode)+\"\\n\"+\\\n",
    "                         inspect.getsource(y_hat)+\"\\n\"+\\\n",
    "                         inspect.getsource(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comprueba tu código. calculamos $\\sum \\hat{y}$ para todos los elementos del dataset y también $J$. los valores esperados son 90.792 y 58.006 respectivamente. No te olvides de **EJECUTAR LA CELDA CON TU SOLUCIÓN DEL EJERCICIO 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.loadtxt(\"data/logregdata.csv\", delimiter=\",\", skiprows=1)\n",
    "X,y = data[:,:2], data[:,2]\n",
    "\n",
    "h_units=4\n",
    "cols = X.shape[1]\n",
    "b1, b2, W1, W2 = np.ones(h_units), 2, np.ones((cols, h_units))*3, np.ones((h_units,1))*4\n",
    "params = encode(b1,b2,W1,W2)\n",
    "print \"sum y_hat\", np.sum(y_hat(params, cols, h_units, X))\n",
    "print \"cost     \", cost(X,y,params,0.4, cols, h_units )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### evaluate your answer before submitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!./run CHECK_SOLUTION PS4_2 $src2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### submit your answer (you must be connected to internet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!./run SUBMIT_SOLUTION PS4_2 $src2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EJERCICIO 3: Organización API `sklearn`\n",
    "\n",
    "Organiza el código de los ejercicios anteriores para que esté conforme con el API de predicción de `sklearn`. En concreto:\n",
    "\n",
    "- el constructor de la clase `SLP` acepta un parámetro que indica el número de neuronas de la capa intermedia y otro el parámetro de regularización $\\lambda$. El tercer parámetro permite al usuario fijar qué parámetros iniciales se usan en el minimizador. Fíjate cómo la función `fit` los usa, o los inicializa aleatoriamente si no están definidos. \n",
    "- las dos primeras variables se guardan en variables de instancia como `self.h_units` y `self.reg` respectivamente y por eso desaparecen de los argumentos de las funciones correspondientes.\n",
    "- la minimización del método `fit` usa `self.init_params` como valores iniciales de los parámetros. Esos valores se inicializan en el constructor\n",
    "- una vez realizada la minización en el método `fit`, el vector codificado de parámetros obtenidos se guarda en la variable de instancia `self.params`\n",
    "- la función `y_hat` ha de funcionar con una matrix en la que en cada fila hay un dato, y ha de devolver un vector con valor por cada dato, al igual que en el ejercicio anterior\n",
    "\n",
    "Observa, adicionalmente, como la función `predict` aplica un umbral a $\\hat{y}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='imgs/slp1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SLP(**args): # hack for inspect to work with classes\n",
    "    from scipy.optimize import minimize\n",
    "    import numpy as np\n",
    "    \n",
    "    class SLP_class:\n",
    "\n",
    "        def __init__(self, h_units, reg=0, init_params=None):\n",
    "            self.h_units = h_units\n",
    "            self.reg     = reg\n",
    "            self.init_params = init_params\n",
    "\n",
    "        def sigm(self, x):\n",
    "            return 1/(1+np.exp(-x))\n",
    "\n",
    "        def encode(self, b1, b2, W1, W2): \n",
    "            return ...\n",
    "\n",
    "        def decode(self, params, nb_cols):\n",
    "            b1 = ...\n",
    "            b2 = ...\n",
    "            W1 = ...\n",
    "            W2 = ...\n",
    "            return b1, b2, W1, W2\n",
    "\n",
    "        def y_hat(self, X, params):\n",
    "            return ...\n",
    "\n",
    "        def fit(self, X,y, verbose=False):\n",
    "\n",
    "            self.init_params = np.random.random(1+self.h_units*2+self.h_units*X.shape[1]) \\\n",
    "                               if self.init_params is None else self.init_params\n",
    "            def cost(p):\n",
    "                return ...\n",
    "\n",
    "            r = minimize(cost, self.init_params, method=\"BFGS\")\n",
    "            self.params = r.x\n",
    "\n",
    "        def predict(self, X):\n",
    "            return (self.y_hat(X, self.params)>.5)*1\n",
    "\n",
    "        def score(self, X,y):\n",
    "            return np.sum(self.predict(X)==y)*1./len(X)\n",
    "        \n",
    "    return SLP_class(**args)\n",
    "\n",
    "import urllib, inspect\n",
    "src3 = urllib.quote_plus(inspect.getsource(SLP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprueba tu código, debería de darte similar a la figura anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import *\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_2Ddata_with_boundary(predict,X,y):\n",
    "    n = 200\n",
    "    mins,maxs = np.min(X,axis=0), np.max(X,axis=0)\n",
    "    mins -= np.abs(mins)*.2\n",
    "    maxs += np.abs(maxs)*.2\n",
    "    d0 = np.linspace(mins[0], maxs[0],n)\n",
    "    d1 = np.linspace(mins[1], maxs[1],n)\n",
    "    gd0,gd1 = np.meshgrid(d0,d1)\n",
    "    D = np.hstack((gd0.reshape(-1,1), gd1.reshape(-1,1)))\n",
    "    p = (predict(D)*1.).reshape((n,n))\n",
    "    plt.contourf(gd0,gd1,p, levels=[-0.1,0.5], alpha=0.5, cmap=plt.cm.Greys)\n",
    "    plt.scatter(X[y==0][:,0], X[y==0][:,1], c=\"blue\")\n",
    "    plt.scatter(X[y==1][:,0], X[y==1][:,1], c=\"red\")\n",
    "\n",
    "data = np.loadtxt(\"data/logregdata.csv\", delimiter=\",\", skiprows=1)\n",
    "X,y = data[:,:2], data[:,2]\n",
    "print X.shape, y.shape\n",
    "plt.figure(figsize=(15,4))\n",
    "ip = np.array([ 0.689641  ,  0.8786391 ,  0.95659198,  0.47073749,  0.24074414,\n",
    "        0.78959323,  0.54514714,  0.89902493,  0.36378902,  0.17810766,\n",
    "        0.39348206,  0.83286214,  0.18947855,  0.12043622,  0.59037094,\n",
    "        0.74393984,  0.17897618,  0.92972173,  0.14988048,  0.08396469,\n",
    "        0.55636004,  0.86317963,  0.07162948,  0.86307293,  0.06824969,\n",
    "        0.55192334,  0.51150851,  0.57932144,  0.32561662,  0.51480763,\n",
    "        0.11084518,  0.21689325,  0.39686863,  0.58469945,  0.32392055,\n",
    "        0.86308447,  0.24791053,  0.60489576,  0.90859133,  0.11697256,\n",
    "        0.74434179])\n",
    "\n",
    "plt.subplot(131); slp = SLP(h_units=10, reg=0., init_params=ip); slp.fit(X,y); plot_2Ddata_with_boundary(slp.predict, X,y)\n",
    "plt.subplot(132); slp = SLP(h_units=10, reg=1e-6, init_params=ip); slp.fit(X,y); plot_2Ddata_with_boundary(slp.predict, X,y)\n",
    "plt.subplot(133); slp = SLP(h_units=10, reg=1e-3, init_params=ip); slp.fit(X,y); plot_2Ddata_with_boundary(slp.predict, X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### evaluate your answer before submitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!./run CHECK_SOLUTION PS4_3 $src3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### submit your answer (you must be connected to internet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!./run SUBMIT_SOLUTION PS4_3 $src3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EJERCICIO 4: Regularización\n",
    "\n",
    "completa la siguiente función para que:\n",
    "\n",
    "- Extraiga los primeros `n` elementos de `X` e `y` en las variables `Xtr` e `ytr`.\n",
    "- Cree y entrene tres redes neuronales con:\n",
    "   - 10 `h_units`\n",
    "   - `reg` igual a $0$, $10^{-5}$ y $10^{-3}$ respectivamente.\n",
    "   - usando el `init_params` pasado como argumento en la propia función.\n",
    "   \n",
    "- El entrenamiento habrá de hacerse con `Xtr` e `ytr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def experiment(X,y, n, init_params):\n",
    "\n",
    "    Xtr, ytr = X[:n], y[:n]\n",
    "\n",
    "    slp1 = SLP(h_units=10, reg=0., init_params=init_params)\n",
    "    slp1.fit(Xtr,ytr)\n",
    "    \n",
    "    slp2 = ...\n",
    "    ... # fit slp2\n",
    "    \n",
    "    slp3 = ...\n",
    "    ... # fit slp3\n",
    "    \n",
    "    return slp1, slp2, slp3\n",
    "\n",
    "import urllib, inspect\n",
    "src4 = urllib.quote_plus(inspect.getsource(experiment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comprueba tu código. observa cómo las gráficas que se generan muestran cómo responde el clasificador a los datos de entrenamiento (los primeros 75 datos) y el resto de los datos (test). Los scores han de ser los siguientes:\n",
    "\n",
    "- SLP1: 1.0 en TRAIN y 0.80 en TEST\n",
    "- SLP2: 1.0 en TRAIN y 0.88 en TEST\n",
    "- SLP3: 0.95 en TRAIN y 0.96 en TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"data/logregdata.csv\", delimiter=\",\", skiprows=1)\n",
    "X,y = data[:,:2], data[:,2]\n",
    "np.random.seed(1022)\n",
    "ip = np.array([ 0.689641  ,  0.8786391 ,  0.95659198,  0.47073749,  0.24074414,\n",
    "        0.78959323,  0.54514714,  0.89902493,  0.36378902,  0.17810766,\n",
    "        0.39348206,  0.83286214,  0.18947855,  0.12043622,  0.59037094,\n",
    "        0.74393984,  0.17897618,  0.92972173,  0.14988048,  0.08396469,\n",
    "        0.55636004,  0.86317963,  0.07162948,  0.86307293,  0.06824969,\n",
    "        0.55192334,  0.51150851,  0.57932144,  0.32561662,  0.51480763,\n",
    "        0.11084518,  0.21689325,  0.39686863,  0.58469945,  0.32392055,\n",
    "        0.86308447,  0.24791053,  0.60489576,  0.90859133,  0.11697256,\n",
    "        0.74434179])\n",
    "\n",
    "n = 75\n",
    "slp1, slp2, slp3 = experiment(X,y, 75, init_params=ip)\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.subplot(231); plot_2Ddata_with_boundary(slp1.predict, X[:n],y[:n]); plt.title(\"SLP1 TRAIN score %.2f\"%slp1.score(X[:n], y[:n]))\n",
    "plt.subplot(232); plot_2Ddata_with_boundary(slp2.predict, X[:n],y[:n]); plt.title(\"SLP2 TRAIN score %.2f\"%slp2.score(X[:n], y[:n]))\n",
    "plt.subplot(233); plot_2Ddata_with_boundary(slp3.predict, X[:n],y[:n]); plt.title(\"SLP3 TRAIN score %.2f\"%slp3.score(X[:n], y[:n]))\n",
    "\n",
    "plt.subplot(234); plot_2Ddata_with_boundary(slp1.predict, X[n:],y[n:]); plt.title(\"SLP1 TEST score %.2f\"%slp1.score(X[n:], y[n:]))\n",
    "plt.subplot(235); plot_2Ddata_with_boundary(slp2.predict, X[n:],y[n:]); plt.title(\"SLP2 TEST score %.2f\"%slp2.score(X[n:], y[n:]))\n",
    "plt.subplot(236); plot_2Ddata_with_boundary(slp3.predict, X[n:],y[n:]); plt.title(\"SLP3 TEST score %.2f\"%slp3.score(X[n:], y[n:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### evaluate your answer before submitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!./run CHECK_SOLUTION PS4_4 $src4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### submit your answer (you must be connected to internet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!./run SUBMIT_SOLUTION PS4_4 $src4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": false,
   "toc_threshold": 6,
   "toc_window_display": false
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
